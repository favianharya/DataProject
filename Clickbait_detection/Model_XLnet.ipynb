{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWjxKwKRyu3U",
        "outputId": "fc17097d-591a-4e4f-bfa3-46e9fd95341d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7cpH1Wh4K8va"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import torch\n",
        "from pytorch_transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification\n",
        "from pytorch_transformers import AdamW\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from tqdm import tqdm, trange\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tokenizers\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"df_train.csv\")\n",
        "df_valid = pd.read_csv(\"df_valid.csv\")\n",
        "df_test = pd.read_csv(\"df_test.csv\")"
      ],
      "metadata": {
        "id": "HVwzBAXmPYIw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "__J7cuphy9eF",
        "outputId": "dc6078c3-fa70-4cef-9a0d-c62f56c8f392"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import XLNetTokenizer, XLNetModel\n",
        "\n",
        "model = XLNetModel.from_pretrained('xlnet-base-cased')"
      ],
      "metadata": {
        "id": "UB4KcrCCxhlV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTW21p2RPB3Z",
        "outputId": "2e9e959e-8282-4c5c-c85d-381b200b50cf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLNetModel(\n",
              "  (word_embedding): Embedding(32000, 768)\n",
              "  (layer): ModuleList(\n",
              "    (0-11): 12 x XLNetLayer(\n",
              "      (rel_attn): XLNetRelativeAttention(\n",
              "        (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): XLNetFeedForward(\n",
              "        (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (activation_function): GELUActivation()\n",
              "      )\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
        "\n",
        "tokenized_texts_train = [tokenizer.tokenize(sent) for sent in df_train['clean_text']]\n",
        "tokenized_texts_valid = [tokenizer.tokenize(sent) for sent in df_valid['clean_text']]\n",
        "tokenized_texts_test = [tokenizer.tokenize(sent) for sent in df_test['clean_text']]\n",
        "\n",
        "print (\"Tokenize the first sentence:\")\n",
        "print (tokenized_texts_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRnYJKcdxwwI",
        "outputId": "09688b8a-3312-4d6b-a376-8b351cf8d23b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenize the first sentence:\n",
            "['▁can', '▁you', '▁', 'ident', 'if', 'i', '▁the', '▁drink', '▁when', '▁out', '▁of', '▁it', '▁', 'bot', 't', 'l']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 150\n",
        "input_ids_train = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts_train]\n",
        "input_ids_train = pad_sequences(input_ids_train, maxlen=MAX_LEN, dtype=\"long\")\n",
        "\n",
        "input_ids_valid = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts_valid]\n",
        "input_ids_valid = pad_sequences(input_ids_valid, maxlen=MAX_LEN, dtype=\"long\")\n",
        "\n",
        "input_ids_test = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts_test]\n",
        "input_ids_test = pad_sequences(input_ids_test, maxlen=MAX_LEN, dtype=\"long\")"
      ],
      "metadata": {
        "id": "dorALFQ_0eFd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create attention masks\n",
        "attention_masks_train = []\n",
        "attention_masks_valid = []\n",
        "attention_masks_test = []\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids_train:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks_train.append(seq_mask)\n",
        "\n",
        "for seq in input_ids_valid:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks_valid.append(seq_mask)\n",
        "\n",
        "for seq in input_ids_test:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks_test.append(seq_mask)"
      ],
      "metadata": {
        "id": "f-RERI8g1oAE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_train = df_train['clickbait']\n",
        "labels_valid = df_valid['clickbait']\n",
        "labels_test = df_test['clickbait']"
      ],
      "metadata": {
        "id": "m8mxPtzw18ze"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Assuming train_labels is a Pandas Series\n",
        "train_labels_array = np.array(labels_train)\n",
        "train_labels = torch.tensor(train_labels_array)\n",
        "train_inputs = torch.tensor(input_ids_train)\n",
        "train_masks = torch.tensor(attention_masks_train)\n",
        "\n",
        "# Similarly, convert other Pandas Series to PyTorch tensors\n",
        "validation_inputs = torch.tensor(input_ids_valid)\n",
        "validation_labels_array = np.array(labels_valid)\n",
        "validation_labels = torch.tensor(validation_labels_array)\n",
        "validation_masks = torch.tensor(attention_masks_valid)\n",
        "\n",
        "test_inputs = torch.tensor(input_ids_test)\n",
        "test_labels_array = np.array(labels_test)\n",
        "test_labels = torch.tensor(test_labels_array)\n",
        "test_masks = torch.tensor(attention_masks_test)\n"
      ],
      "metadata": {
        "id": "XeDrrhxT1__2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates torch dataloaders for training and validation sets\n",
        "batch_size = 64\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "ujr2VAZz-XCC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import XLNetForSequenceClassification, XLNetTokenizer"
      ],
      "metadata": {
        "id": "LE4xw0JTG9rs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load XLNEtForSequenceClassification, the pretrained XLNet model with a single linear classification layer on top.\n",
        "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=2)\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwM6sw6w4dwI",
        "outputId": "f3857c35-2ef9-4dbb-9757-8231a5f130dc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'sequence_summary.summary.bias', 'logits_proj.weight', 'sequence_summary.summary.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLNetForSequenceClassification(\n",
              "  (transformer): XLNetModel(\n",
              "    (word_embedding): Embedding(32000, 768)\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (sequence_summary): SequenceSummary(\n",
              "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "    (first_dropout): Identity()\n",
              "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (logits_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]"
      ],
      "metadata": {
        "id": "d-p9VL7c44Mw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This variable contains all of the hyperparemeter information our training loop needs\n",
        "optimizer = AdamW(optimizer_grouped_parameters,\n",
        "                     lr=1e-5)"
      ],
      "metadata": {
        "id": "S2m3MNN_4-AI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "val_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for epoch_num in trange(epochs, desc=\"Epoch\"):\n",
        " # Training\n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "\n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  tr_accuracy = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      # Unpack the inputs from our dataloader\n",
        "      b_input_ids, b_input_mask, b_labels = batch\n",
        "      # Clear out the gradients (by default they accumulate)\n",
        "      optimizer.zero_grad()\n",
        "      # Forward pass\n",
        "      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "      loss = outputs[0]\n",
        "      logits = outputs[1]\n",
        "      train_loss_set.append(loss.item())\n",
        "\n",
        "      # Calculate training accuracy\n",
        "      preds = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
        "      labels = b_labels.to('cpu').numpy()\n",
        "      tr_accuracy += accuracy_score(labels, preds)\n",
        "\n",
        "      # Backward pass\n",
        "      loss.backward()\n",
        "      # Update parameters and take a step using the computed gradient\n",
        "      optimizer.step()\n",
        "\n",
        "      # Update tracking variables\n",
        "      tr_loss += loss.item()\n",
        "      nb_tr_examples += b_input_ids.size(0)\n",
        "      nb_tr_steps += 1\n",
        "\n",
        "    # Calculate and print average training accuracy\n",
        "  average_tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "\n",
        "\n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables\n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "  val_loss_set = []\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "      logits = output[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "    # Log validation loss\n",
        "    val_loss_set.append(loss.item())\n",
        "\n",
        "  average_val_loss = sum(val_loss_set) / len(val_loss_set)\n",
        "\n",
        "\n",
        "  print(\n",
        "    f'Epochs: {epoch_num + 1} | Train Loss: {tr_loss/nb_tr_steps: .3f} '\n",
        "    f'| Train Accuracy: {average_tr_accuracy: .3f} '\n",
        "    f'| Val Loss: {average_val_loss: .3f} '\n",
        "    f'| Val Accuracy: {eval_accuracy/nb_eval_steps: .3f} ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy5O9pcz5Ann",
        "outputId": "5455c084-dcbc-4460-a868-0061b4bdc9d2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:  25%|██▌       | 1/4 [14:45<44:16, 885.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  0.054 | Train Accuracy:  0.981 | Val Loss:  0.203 | Val Accuracy:  0.967 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  50%|█████     | 2/4 [29:29<29:29, 884.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  0.039 | Train Accuracy:  0.986 | Val Loss:  0.174 | Val Accuracy:  0.966 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  75%|███████▌  | 3/4 [44:13<14:44, 884.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  0.029 | Train Accuracy:  0.990 | Val Loss:  0.028 | Val Accuracy:  0.969 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 4/4 [58:56<00:00, 884.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss:  0.018 | Train Accuracy:  0.994 | Val Loss:  0.009 | Val Accuracy:  0.966 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing terhadap Dataset Testing\n",
        "# Testing\n",
        "\n",
        "# Put model in evaluation mode to evaluate on the test set\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "test_accuracy = 0\n",
        "nb_test_steps = 0\n",
        "\n",
        "# Evaluate on the test set\n",
        "for batch in test_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients\n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions\n",
        "        output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "        logits = output[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_test_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "    test_accuracy += tmp_test_accuracy\n",
        "    nb_test_steps += 1\n",
        "\n",
        "# Calculate and print average testing accuracy\n",
        "average_test_accuracy = test_accuracy / nb_test_steps\n",
        "print(f'Test Accuracy: {average_test_accuracy:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_AwwOk7TTC6",
        "outputId": "f59c70d5-a344-4fd3-a328-64b89ee4187b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3hW1OVyn382X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}